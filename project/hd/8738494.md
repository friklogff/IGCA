# 水体污染等级分类

### 1、解压数据集
1. 数据集格式：train中有图片和对应标注好标签和污染等级的csv文件；；test文件只有图片。
1. train的数据集8:2划分为训练集和验证集



```python
!pwd   #显示目录
!unzip -oq data/data101229/data.zip
```

    /home/aistudio


### 2、导入库


```python
# 导入所需要的库
from sklearn.utils import shuffle
import os
import pandas as pd
import numpy as np
from PIL import Image

import paddle
import paddle.nn as nn
from paddle.io import Dataset
import paddle.vision.transforms as T
import paddle.nn.functional as F
from paddle.metric import Accuracy

import warnings
warnings.filterwarnings("ignore")
```

### 3、EDA（Exploratory Data Analysis）与数据预处理
数据EDA，这里是提供思路，非必须

&emsp;&emsp;探索性数据分析（Exploratory Data Analysis，简称EDA），是指对已有的数据（原始数据）进行分析探索，通过作图、制表、方程拟合、计算特征量等手段探索数据的结构和规律的一种数据分析方法。一般来说，我们最初接触到数据的时候往往是毫无头绪的，不知道如何下手，这时候探索性数据分析就非常有效。

&emsp;&emsp;对于图像分类任务，我们通常首先应该统计出每个类别的数量，查看训练集的数据分布情况。通过数据分布情况分析赛题，形成解题思路。（洞察数据的本质很重要。）


```python
# 数据EDA
df = pd.read_csv('data/train_data/train_label.csv')
d = df['label'].hist().get_figure()
# d.savefig('2.jpg')
print(d)
```

    Figure(640x480)



```python
# 读取数据
train_images = pd.read_csv('data/train_data/train_label.csv', usecols=['image_name','label'])  # 读取文件名和类别
# print(train_images)

# labelshuffling，定义标签打乱模块
def labelShuffling(dataFrame, groupByName='label'):

    groupDataFrame = dataFrame.groupby(by=[groupByName])
    labels = groupDataFrame.size()
    print("length of label is ", len(labels))
    maxNum = max(labels)
    lst = pd.DataFrame()
    for i in range(len(labels)):
        print("Processing label  :", i)
        tmpGroupBy = groupDataFrame.get_group(i)
        createdShuffleLabels = np.random.permutation(np.array(range(maxNum))) % labels[i]  # 随机排列组合
        print("Num of the label is : ", labels[i])
        lst=lst.append(tmpGroupBy.iloc[createdShuffleLabels], ignore_index=True)
        # print("Done")
    # lst.to_csv('test1.csv', index=False)
    return lst

#####由于数据集是按类规则排放的，应该先打乱再划分吧？？？？？？？
"""
df = labelShuffling(train_images)
df = shuffle(df)
# 划分训练集和验证集 8:2;;后面好像测试集直接引用了验证集的图
all_size = len(train_images)
print("训练集大小：", all_size)
train_size = int(all_size * 0.8)
train_image_list = df[:train_size]
val_image_list = df[train_size:]
"""
# 进行训练集和测试集划分，按照先打乱后划分原则
all_size = len(train_images)
print("训练集大小：", all_size)
train_size = int(all_size * 0.8)
train_image_list = train_images[:train_size]
val_image_list = train_images[train_size:]

df = labelShuffling(train_image_list)
df = shuffle(df)
print("shuffle后数据集大小：", len(df))

train_image_path_list = df['image_name'].values
label_list = df['label'].values
label_list = paddle.to_tensor(label_list, dtype='int64')
train_label_list = paddle.nn.functional.one_hot(label_list, num_classes=4)

val_image_path_list = val_image_list['image_name'].values
val_label_list = val_image_list['label'].values
val_label_list = paddle.to_tensor(val_label_list, dtype='int64')
val_label_list = paddle.nn.functional.one_hot(val_label_list, num_classes=4)
```

    训练集大小： 1922
    length of label is  4
    Processing label  : 0
    Num of the label is :  435
    Processing label  : 1
    Num of the label is :  423
    Processing label  : 2
    Num of the label is :  487
    Processing label  : 3
    Num of the label is :  192
    shuffle后数据集大小： 1948


    W0102 10:46:58.787335    98 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 10.1
    W0102 10:46:58.795149    98 device_context.cc:422] device: 0, cuDNN Version: 7.6.



```python
# 定义数据预处理,数据增广方法
data_transforms = T.Compose([
    T.RandomResizedCrop(224, scale=(0.8, 1.2), ratio=(3. / 4, 4. / 3), interpolation='bilinear'),
    T.RandomHorizontalFlip(),
    T.RandomVerticalFlip(),
    T.RandomRotation(15),
    T.Transpose(),    # HWC -> CHW
    T.Normalize(
        mean=[127.5, 127.5, 127.5],        # 归一化
        std=[127.5, 127.5, 127.5],
        to_rgb=True)    
])
```


```python
# 构建Dataset
#需要用GPU跑
import paddle
class MyDataset(paddle.io.Dataset):
    """
    步骤一：继承paddle.io.Dataset类
    """
    def __init__(self, train_img_list, val_img_list, train_label_list, val_label_list, mode='train'):
        """
        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集;;
        ### 应该是验证集吧；直接将训练集数据分成了训练和验证，还得想想怎么测试测试集的图片
        """
        super(MyDataset, self).__init__()
        self.img = []
        self.label = []
        # 借助pandas读csv的库
        self.train_images = train_img_list
        self.val_images = val_img_list  ###############
        self.train_label = train_label_list
        self.val_label = val_label_list  ##############
        if mode == 'train':
            # 读train_images的数据
            for img,la in zip(self.train_images, self.train_label):
                self.img.append('data/train_data/train_image/' + img)
                self.label.append(la)
        else:
            # 读test_images的数据
            for img,la in zip(self.val_images, self.val_label):   #############
                self.img.append('data/train_data/train_image/' + img)
                self.label.append(la)

         

    def load_img(self, image_path):
        # 实际使用时使用Pillow相关库进行图片读取即可，这里我们对数据先做个模拟
        image = Image.open(image_path).convert('RGB')
        return image

    def __getitem__(self, index):
        """
        步骤三：实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）
        """
        image = self.load_img(self.img[index])
        label = self.label[index]
        # label = paddle.to_tensor(label)
        
        return data_transforms(image), paddle.nn.functional.label_smooth(label)

    def __len__(self):
        """
        步骤四：实现__len__方法，返回数据集总数目
        """
        return len(self.img)

BATCH_SIZE = 128
PLACE = paddle.CUDAPlace(0)

# train_loader
train_dataset = MyDataset(
    train_img_list=train_image_path_list, 
    val_img_list=val_image_path_list, 
    train_label_list=train_label_list, 
    val_label_list=val_label_list, 
    mode='train')
train_loader = paddle.io.DataLoader(
    train_dataset, 
    places=PLACE, 
    batch_size=BATCH_SIZE, 
    shuffle=True, 
    num_workers=0)

# val_loader
val_dataset = MyDataset(
    train_img_list=train_image_path_list, 
    val_img_list=val_image_path_list, 
    train_label_list=train_label_list, 
    val_label_list=val_label_list, 
    mode='test')
val_loader = paddle.io.DataLoader(
    val_dataset, 
    places=PLACE, 
    batch_size=BATCH_SIZE, 
    shuffle=False, 
    num_workers=0)
```


```python
# 定义模型
class MyNet(paddle.nn.Sequential):
    def __init__(self):
        super(MyNet, self).__init__(
                paddle.vision.models.mobilenet_v2(pretrained=True, scale=1.0),
                paddle.nn.Linear(1000, 4)
        )

model = MyNet()
model = paddle.Model(model)
model.summary((1, 3, 224, 224))
```

    100%|██████████| 20795/20795 [00:03<00:00, 6784.81it/s] 


    -------------------------------------------------------------------------------
       Layer (type)         Input Shape          Output Shape         Param #    
    ===============================================================================
         Conv2D-1        [[1, 3, 224, 224]]   [1, 32, 112, 112]         864      
       BatchNorm2D-1    [[1, 32, 112, 112]]   [1, 32, 112, 112]         128      
          ReLU6-1       [[1, 32, 112, 112]]   [1, 32, 112, 112]          0       
         Conv2D-2       [[1, 32, 112, 112]]   [1, 32, 112, 112]         288      
       BatchNorm2D-2    [[1, 32, 112, 112]]   [1, 32, 112, 112]         128      
          ReLU6-2       [[1, 32, 112, 112]]   [1, 32, 112, 112]          0       
         Conv2D-3       [[1, 32, 112, 112]]   [1, 16, 112, 112]         512      
       BatchNorm2D-3    [[1, 16, 112, 112]]   [1, 16, 112, 112]         64       
    InvertedResidual-1  [[1, 32, 112, 112]]   [1, 16, 112, 112]          0       
         Conv2D-4       [[1, 16, 112, 112]]   [1, 96, 112, 112]        1,536     
       BatchNorm2D-4    [[1, 96, 112, 112]]   [1, 96, 112, 112]         384      
          ReLU6-3       [[1, 96, 112, 112]]   [1, 96, 112, 112]          0       
         Conv2D-5       [[1, 96, 112, 112]]    [1, 96, 56, 56]          864      
       BatchNorm2D-5     [[1, 96, 56, 56]]     [1, 96, 56, 56]          384      
          ReLU6-4        [[1, 96, 56, 56]]     [1, 96, 56, 56]           0       
         Conv2D-6        [[1, 96, 56, 56]]     [1, 24, 56, 56]         2,304     
       BatchNorm2D-6     [[1, 24, 56, 56]]     [1, 24, 56, 56]          96       
    InvertedResidual-2  [[1, 16, 112, 112]]    [1, 24, 56, 56]           0       
         Conv2D-7        [[1, 24, 56, 56]]     [1, 144, 56, 56]        3,456     
       BatchNorm2D-7     [[1, 144, 56, 56]]    [1, 144, 56, 56]         576      
          ReLU6-5        [[1, 144, 56, 56]]    [1, 144, 56, 56]          0       
         Conv2D-8        [[1, 144, 56, 56]]    [1, 144, 56, 56]        1,296     
       BatchNorm2D-8     [[1, 144, 56, 56]]    [1, 144, 56, 56]         576      
          ReLU6-6        [[1, 144, 56, 56]]    [1, 144, 56, 56]          0       
         Conv2D-9        [[1, 144, 56, 56]]    [1, 24, 56, 56]         3,456     
       BatchNorm2D-9     [[1, 24, 56, 56]]     [1, 24, 56, 56]          96       
    InvertedResidual-3   [[1, 24, 56, 56]]     [1, 24, 56, 56]           0       
         Conv2D-10       [[1, 24, 56, 56]]     [1, 144, 56, 56]        3,456     
      BatchNorm2D-10     [[1, 144, 56, 56]]    [1, 144, 56, 56]         576      
          ReLU6-7        [[1, 144, 56, 56]]    [1, 144, 56, 56]          0       
         Conv2D-11       [[1, 144, 56, 56]]    [1, 144, 28, 28]        1,296     
      BatchNorm2D-11     [[1, 144, 28, 28]]    [1, 144, 28, 28]         576      
          ReLU6-8        [[1, 144, 28, 28]]    [1, 144, 28, 28]          0       
         Conv2D-12       [[1, 144, 28, 28]]    [1, 32, 28, 28]         4,608     
      BatchNorm2D-12     [[1, 32, 28, 28]]     [1, 32, 28, 28]          128      
    InvertedResidual-4   [[1, 24, 56, 56]]     [1, 32, 28, 28]           0       
         Conv2D-13       [[1, 32, 28, 28]]     [1, 192, 28, 28]        6,144     
      BatchNorm2D-13     [[1, 192, 28, 28]]    [1, 192, 28, 28]         768      
          ReLU6-9        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0       
         Conv2D-14       [[1, 192, 28, 28]]    [1, 192, 28, 28]        1,728     
      BatchNorm2D-14     [[1, 192, 28, 28]]    [1, 192, 28, 28]         768      
         ReLU6-10        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0       
         Conv2D-15       [[1, 192, 28, 28]]    [1, 32, 28, 28]         6,144     
      BatchNorm2D-15     [[1, 32, 28, 28]]     [1, 32, 28, 28]          128      
    InvertedResidual-5   [[1, 32, 28, 28]]     [1, 32, 28, 28]           0       
         Conv2D-16       [[1, 32, 28, 28]]     [1, 192, 28, 28]        6,144     
      BatchNorm2D-16     [[1, 192, 28, 28]]    [1, 192, 28, 28]         768      
         ReLU6-11        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0       
         Conv2D-17       [[1, 192, 28, 28]]    [1, 192, 28, 28]        1,728     
      BatchNorm2D-17     [[1, 192, 28, 28]]    [1, 192, 28, 28]         768      
         ReLU6-12        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0       
         Conv2D-18       [[1, 192, 28, 28]]    [1, 32, 28, 28]         6,144     
      BatchNorm2D-18     [[1, 32, 28, 28]]     [1, 32, 28, 28]          128      
    InvertedResidual-6   [[1, 32, 28, 28]]     [1, 32, 28, 28]           0       
         Conv2D-19       [[1, 32, 28, 28]]     [1, 192, 28, 28]        6,144     
      BatchNorm2D-19     [[1, 192, 28, 28]]    [1, 192, 28, 28]         768      
         ReLU6-13        [[1, 192, 28, 28]]    [1, 192, 28, 28]          0       
         Conv2D-20       [[1, 192, 28, 28]]    [1, 192, 14, 14]        1,728     
      BatchNorm2D-20     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      
         ReLU6-14        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       
         Conv2D-21       [[1, 192, 14, 14]]    [1, 64, 14, 14]        12,288     
      BatchNorm2D-21     [[1, 64, 14, 14]]     [1, 64, 14, 14]          256      
    InvertedResidual-7   [[1, 32, 28, 28]]     [1, 64, 14, 14]           0       
         Conv2D-22       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576     
      BatchNorm2D-22     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-15        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-23       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456     
      BatchNorm2D-23     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-16        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-24       [[1, 384, 14, 14]]    [1, 64, 14, 14]        24,576     
      BatchNorm2D-24     [[1, 64, 14, 14]]     [1, 64, 14, 14]          256      
    InvertedResidual-8   [[1, 64, 14, 14]]     [1, 64, 14, 14]           0       
         Conv2D-25       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576     
      BatchNorm2D-25     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-17        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-26       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456     
      BatchNorm2D-26     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-18        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-27       [[1, 384, 14, 14]]    [1, 64, 14, 14]        24,576     
      BatchNorm2D-27     [[1, 64, 14, 14]]     [1, 64, 14, 14]          256      
    InvertedResidual-9   [[1, 64, 14, 14]]     [1, 64, 14, 14]           0       
         Conv2D-28       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576     
      BatchNorm2D-28     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-19        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-29       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456     
      BatchNorm2D-29     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-20        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-30       [[1, 384, 14, 14]]    [1, 64, 14, 14]        24,576     
      BatchNorm2D-30     [[1, 64, 14, 14]]     [1, 64, 14, 14]          256      
    InvertedResidual-10  [[1, 64, 14, 14]]     [1, 64, 14, 14]           0       
         Conv2D-31       [[1, 64, 14, 14]]     [1, 384, 14, 14]       24,576     
      BatchNorm2D-31     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-21        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-32       [[1, 384, 14, 14]]    [1, 384, 14, 14]        3,456     
      BatchNorm2D-32     [[1, 384, 14, 14]]    [1, 384, 14, 14]        1,536     
         ReLU6-22        [[1, 384, 14, 14]]    [1, 384, 14, 14]          0       
         Conv2D-33       [[1, 384, 14, 14]]    [1, 96, 14, 14]        36,864     
      BatchNorm2D-33     [[1, 96, 14, 14]]     [1, 96, 14, 14]          384      
    InvertedResidual-11  [[1, 64, 14, 14]]     [1, 96, 14, 14]           0       
         Conv2D-34       [[1, 96, 14, 14]]     [1, 576, 14, 14]       55,296     
      BatchNorm2D-34     [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304     
         ReLU6-23        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0       
         Conv2D-35       [[1, 576, 14, 14]]    [1, 576, 14, 14]        5,184     
      BatchNorm2D-35     [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304     
         ReLU6-24        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0       
         Conv2D-36       [[1, 576, 14, 14]]    [1, 96, 14, 14]        55,296     
      BatchNorm2D-36     [[1, 96, 14, 14]]     [1, 96, 14, 14]          384      
    InvertedResidual-12  [[1, 96, 14, 14]]     [1, 96, 14, 14]           0       
         Conv2D-37       [[1, 96, 14, 14]]     [1, 576, 14, 14]       55,296     
      BatchNorm2D-37     [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304     
         ReLU6-25        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0       
         Conv2D-38       [[1, 576, 14, 14]]    [1, 576, 14, 14]        5,184     
      BatchNorm2D-38     [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304     
         ReLU6-26        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0       
         Conv2D-39       [[1, 576, 14, 14]]    [1, 96, 14, 14]        55,296     
      BatchNorm2D-39     [[1, 96, 14, 14]]     [1, 96, 14, 14]          384      
    InvertedResidual-13  [[1, 96, 14, 14]]     [1, 96, 14, 14]           0       
         Conv2D-40       [[1, 96, 14, 14]]     [1, 576, 14, 14]       55,296     
      BatchNorm2D-40     [[1, 576, 14, 14]]    [1, 576, 14, 14]        2,304     
         ReLU6-27        [[1, 576, 14, 14]]    [1, 576, 14, 14]          0       
         Conv2D-41       [[1, 576, 14, 14]]     [1, 576, 7, 7]         5,184     
      BatchNorm2D-41      [[1, 576, 7, 7]]      [1, 576, 7, 7]         2,304     
         ReLU6-28         [[1, 576, 7, 7]]      [1, 576, 7, 7]           0       
         Conv2D-42        [[1, 576, 7, 7]]      [1, 160, 7, 7]        92,160     
      BatchNorm2D-42      [[1, 160, 7, 7]]      [1, 160, 7, 7]          640      
    InvertedResidual-14  [[1, 96, 14, 14]]      [1, 160, 7, 7]           0       
         Conv2D-43        [[1, 160, 7, 7]]      [1, 960, 7, 7]        153,600    
      BatchNorm2D-43      [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840     
         ReLU6-29         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0       
         Conv2D-44        [[1, 960, 7, 7]]      [1, 960, 7, 7]         8,640     
      BatchNorm2D-44      [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840     
         ReLU6-30         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0       
         Conv2D-45        [[1, 960, 7, 7]]      [1, 160, 7, 7]        153,600    
      BatchNorm2D-45      [[1, 160, 7, 7]]      [1, 160, 7, 7]          640      
    InvertedResidual-15   [[1, 160, 7, 7]]      [1, 160, 7, 7]           0       
         Conv2D-46        [[1, 160, 7, 7]]      [1, 960, 7, 7]        153,600    
      BatchNorm2D-46      [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840     
         ReLU6-31         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0       
         Conv2D-47        [[1, 960, 7, 7]]      [1, 960, 7, 7]         8,640     
      BatchNorm2D-47      [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840     
         ReLU6-32         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0       
         Conv2D-48        [[1, 960, 7, 7]]      [1, 160, 7, 7]        153,600    
      BatchNorm2D-48      [[1, 160, 7, 7]]      [1, 160, 7, 7]          640      
    InvertedResidual-16   [[1, 160, 7, 7]]      [1, 160, 7, 7]           0       
         Conv2D-49        [[1, 160, 7, 7]]      [1, 960, 7, 7]        153,600    
      BatchNorm2D-49      [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840     
         ReLU6-33         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0       
         Conv2D-50        [[1, 960, 7, 7]]      [1, 960, 7, 7]         8,640     
      BatchNorm2D-50      [[1, 960, 7, 7]]      [1, 960, 7, 7]         3,840     
         ReLU6-34         [[1, 960, 7, 7]]      [1, 960, 7, 7]           0       
         Conv2D-51        [[1, 960, 7, 7]]      [1, 320, 7, 7]        307,200    
      BatchNorm2D-51      [[1, 320, 7, 7]]      [1, 320, 7, 7]         1,280     
    InvertedResidual-17   [[1, 160, 7, 7]]      [1, 320, 7, 7]           0       
         Conv2D-52        [[1, 320, 7, 7]]     [1, 1280, 7, 7]        409,600    
      BatchNorm2D-52     [[1, 1280, 7, 7]]     [1, 1280, 7, 7]         5,120     
         ReLU6-35        [[1, 1280, 7, 7]]     [1, 1280, 7, 7]           0       
    AdaptiveAvgPool2D-1  [[1, 1280, 7, 7]]     [1, 1280, 1, 1]           0       
         Dropout-1          [[1, 1280]]           [1, 1280]              0       
         Linear-1           [[1, 1280]]           [1, 1000]          1,281,000   
       MobileNetV2-1     [[1, 3, 224, 224]]       [1, 1000]              0       
         Linear-2           [[1, 1000]]             [1, 4]             4,004     
    ===============================================================================
    Total params: 3,542,988
    Trainable params: 3,474,764
    Non-trainable params: 68,224
    -------------------------------------------------------------------------------
    Input size (MB): 0.57
    Forward/backward pass size (MB): 152.88
    Params size (MB): 13.52
    Estimated Total Size (MB): 166.97
    -------------------------------------------------------------------------------
    





    {'total_params': 3542988, 'trainable_params': 3474764}



### 模型训练 Trick
具体内容见原项目


```python
def make_optimizer(parameters=None, momentum=0.9, weight_decay=5e-4, boundaries=None, values=None):
    
    lr_scheduler = paddle.optimizer.lr.PiecewiseDecay(
        boundaries=boundaries, 
        values=values,
        verbose=False)

    lr_scheduler = paddle.optimizer.lr.LinearWarmup(
        learning_rate=base_lr,
        warmup_steps=20,
        start_lr=base_lr / 5.,
        end_lr=base_lr,
        verbose=False)

    # optimizer = paddle.optimizer.Momentum(
    #     learning_rate=lr_scheduler,
    #     weight_decay=weight_decay,
    #     momentum=momentum,
    #     parameters=parameters)

    optimizer = paddle.optimizer.Adam(
        learning_rate=lr_scheduler,
        weight_decay=weight_decay,
        parameters=parameters)

    return optimizer


base_lr = 0.001
boundaries = [33, 44]

optimizer = make_optimizer(boundaries=boundaries, values=[base_lr, base_lr*0.1, base_lr*0.01], parameters=model.parameters())

model.prepare(
    optimizer=optimizer,
    loss=paddle.nn.CrossEntropyLoss(soft_label=True),
    metrics=paddle.metric.Accuracy(topk=(1, 5))
)

# callbacks
visualdl = paddle.callbacks.VisualDL('./visualdl/MobileNetV2')
earlystop = paddle.callbacks.EarlyStopping( # acc不在上升时停止
    'acc',
    mode='max',
    patience=2,
    verbose=1,
    min_delta=0,
    baseline=None,
    save_best_model=True)

model.fit(
    train_loader,
    val_loader,
    epochs=50,
    save_freq=5,
    save_dir='checkpoint/MobileNetV2',
    callbacks=[visualdl, earlystop],
    verbose=1
)
```

    The loss value printed in the log is the current step, and the metric is the average value of previous steps.
    Epoch 1/50



```python
# 训练模型保存
model.save('work/model/best_model')  # save for training
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-1-e4cce472b402> in <module>
          1 # 训练模型保存
    ----> 2 model.save('work/model/best_model')  # save for training
    

    NameError: name 'model' is not defined


### 模型评估


```python
model.load('work/model/best_model')
model.prepare(
    loss=paddle.nn.CrossEntropyLoss(soft_label=True),
    metrics=paddle.metric.Accuracy()
)
result = model.evaluate(val_loader, batch_size=1, verbose=1)
print(result)
```

    Eval begin...
    step 4/4 [==============================] - loss: 0.3944 - acc: 0.8156 - 2s/step
    Eval samples: 385
    {'loss': [0.39442146], 'acc': 0.8155844155844156}



```python
model.save('work/model/best_model', training=False)  # save for inference
```
